{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE\n",
    "---\n",
    "The data is Images\n",
    "\n",
    "1.We can download manually images from the google\n",
    "\n",
    "2.We can find the dataset from kaggle\n",
    "\n",
    "3.We can build a image web crawler\n",
    "\n",
    "4.Use python libraries to scrape the images using bing(bing is a search engine like google)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "1.Resizing\n",
    "\n",
    "2.Flattening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # to go through different folders\n",
    "import matplotlib.pyplot as plt # used for displaying the image\n",
    "import numpy as np #used for numerical computing\n",
    "from skimage.io import imread #to read an image\n",
    "from skimage.transform import resize # we need to convert all the images into same size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flatten method\n",
    "To converting a matrix to vector or how to converting a 2D array to 1D we use flatten method\n",
    "\n",
    "Images are in the form of matrix.They should be flattened. They can be flattened by using flatten() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.31648802, 0.51665359, 0.63822222, ..., 0.20864488, 0.13953813,\n",
       "       0.08281481])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = []\n",
    "images = []\n",
    "flat_data = []\n",
    "\n",
    "datadir = 'E:\\Image Classification\\Data'\n",
    "categories = ['cats','dogs','panda']\n",
    "\n",
    "for category in categories:\n",
    "  class_num = categories.index(category) #Label encoding the values\n",
    "  path = os.path.join(datadir,category) #create path to use all the images\n",
    "  for img in os.listdir(path):\n",
    "    img_array=imread(os.path.join(path,img))\n",
    "    img_resize = resize(img_array,(150,150,3)) #normalizes the value 0 to 1\n",
    "    flat_data.append(img_resize.flatten())\n",
    "    images.append(img_resize)\n",
    "    target.append(class_num)\n",
    "\n",
    "flat_data = np.array(flat_data)\n",
    "target = np.array(target)\n",
    "images = np.array(images)\n",
    "flat_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 2, 2, 2])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2]), array([1000, 1000, 1000], dtype=int64))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(target,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 3 artists>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "unique,count=np.unique(target,return_counts=True)\n",
    "plt.bar(categories,count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting data for train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(flat_data,target,test_size=0.3,random_state=109)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6411111111111111\n",
      "Cross validation: [0.65714286 0.67142857 0.67142857 0.63333333 0.62142857]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "clf = svm.SVC(C=4,kernel='rbf',gamma='scale')\n",
    "clf.fit(x_train,y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "print(\"Accuracy:\",accuracy_score(y_pred,y_test))\n",
    "print(\"Cross validation:\",cross_val_score(clf,x_train,y_train,cv=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save tha model using pickle library\n",
    "import pickle\n",
    "pickle.dump(clf,open('img_model_svm.p','wb'))\n",
    "model = pickle.load(open('img_model_svm.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter the url:http://cdn.akc.org/content/article-body-image/samoyed_puppy_dog_pictures.jpg\n",
      "predicted output:dogs\n"
     ]
    }
   ],
   "source": [
    "#testing for a new image\n",
    "flat_data = []\n",
    "url = input(\"enter the url:\")\n",
    "img = imread(url)\n",
    "img_resize = resize(img,(150,150,3))\n",
    "flat_data.append(img_resize.flatten())\n",
    "flat_data = np.array(flat_data)\n",
    "\n",
    "y_out = model.predict(flat_data)\n",
    "y_out = categories[y_out[0]]\n",
    "print(f\"predicted output:{y_out}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6455555555555555\n",
      "Cross validation: [0.61666667 0.66190476 0.62142857 0.64047619 0.6452381 ]\n"
     ]
    }
   ],
   "source": [
    "# The Higher number of trees(n_estimators) give you better performance but makes your code slower.\n",
    "# The max_depth of a tree in Random Forest is defined as the longest path between the root node and the leaf node\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "\n",
    "clf1 = RandomForestClassifier(n_estimators=150, max_depth=None,min_samples_split=2, random_state=1)\n",
    "clf1.fit(x_train,y_train)\n",
    "y_pred = clf1.predict(x_test)\n",
    "print(\"Accuracy:\",accuracy_score(y_pred,y_test))\n",
    "print(\"Cross validation:\",cross_val_score(clf1,x_train,y_train,cv=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save tha model using pickle library\n",
    "import pickle\n",
    "pickle.dump(clf,open('img_model_rf.p','wb'))\n",
    "model = pickle.load(open('img_model_rf.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter the url:https://upload.wikimedia.org/wikipedia/commons/c/c7/Tabby_cat_with_blue_eyes-3336579.jpg\n",
      "predicted output:cats\n"
     ]
    }
   ],
   "source": [
    "#testing for a new image\n",
    "flat_data = []\n",
    "url = input(\"enter the url:\")\n",
    "img = imread(url)\n",
    "img_resize = resize(img,(150,150,3))\n",
    "flat_data.append(img_resize.flatten())\n",
    "flat_data = np.array(flat_data)\n",
    "\n",
    "y_out = model.predict(flat_data)\n",
    "y_out = categories[y_out[0]]\n",
    "print(f\"predicted output:{y_out}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5077777777777778\n",
      "Cross validation: [0.48809524 0.52142857 0.50714286 0.51904762 0.48095238]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "\n",
    "decision_tree = DecisionTreeClassifier(random_state=1, max_depth=None)\n",
    "clf2 = decision_tree.fit(x_train,y_train)\n",
    "y_pred = clf2.predict(x_test)\n",
    "print(\"Accuracy:\",accuracy_score(y_pred,y_test))\n",
    "print(\"Cross validation:\",cross_val_score(clf2,x_train,y_train,cv=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save tha model using pickle library\n",
    "import pickle\n",
    "pickle.dump(clf,open('img_model_DTC.p','wb'))\n",
    "model = pickle.load(open('img_model_DTC.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter the url:https://upload.wikimedia.org/wikipedia/commons/c/c7/Tabby_cat_with_blue_eyes-3336579.jpg\n",
      "predicted output:cats\n"
     ]
    }
   ],
   "source": [
    "#testing for a new image\n",
    "flat_data = []\n",
    "url = input(\"enter the url:\")\n",
    "img = imread(url)\n",
    "img_resize = resize(img,(150,150,3))\n",
    "flat_data.append(img_resize.flatten())\n",
    "flat_data = np.array(flat_data)\n",
    "\n",
    "y_out = model.predict(flat_data)\n",
    "y_out = categories[y_out[0]]\n",
    "print(f\"predicted output:{y_out}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
